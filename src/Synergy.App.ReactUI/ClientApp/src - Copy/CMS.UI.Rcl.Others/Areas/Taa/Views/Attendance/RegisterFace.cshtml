@using CMS.Common;

@model IUserContext;

@{
    Layout = "/Views/Shared/_PopupLayout.cshtml";
}

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>

@*<script src="~/js/FaceAPI/face-api.js"></script>
    <script src="~/js/FaceAPI/commons.js"></script>
    <script src="~/js/FaceAPI/faceDetectionControls.js"></script>*@
<link href="~/js/FaceAPI/styles.css" rel="stylesheet" />

<script>

    var faceDetectionOptions = new faceapi.TinyFaceDetectorOptions({ inputSize, scoreThreshold });
    var faceDetectionNet = faceapi.nets.tinyFaceDetector;
    var faceMatcher;
    var withBoxes = true;
    var caputreImageIndex = 1;
    var descriptors = [];
    var capturedCanvas = [];
    var labeldescriptors = [];

    async function onPlay() {

            const videoEl = $('#inputVideo').get(0)

            if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
                return setTimeout(() => onPlay())

            if (caputreImageIndex < 6) {
                const options = getFaceDetectorOptions()

                const useTinyModel = true
                //const result = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks(useTinyModel)
                const result = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks(useTinyModel)
                    .withFaceDescriptor()


                const canvas = $('#overlay').get(0)


                //var res = await faceapi.detectAllFaces(videoEl, options).withFaceLandmarks(useTinyModel)
                //const faceImages = await faceapi.extractFaces(videoEl, res)
                //    displayExtractedFaces(faceImages);
                //
                //updateTimeStats(Date.now() - ts)

                if (result) {
                    descriptors.push(result.descriptor);
                    const canvas = $('#overlay').get(0)
                    const dims = faceapi.matchDimensions(canvas, videoEl, true)
                    const resizedResult = faceapi.resizeResults(result, dims)

                    if (withBoxes) {
                        faceapi.draw.drawDetections(canvas, resizedResult)
                    }
                    faceapi.draw.drawFaceLandmarks(canvas, resizedResult)
                }

                setTimeout(async () => { await capture(); onPlay() })
            } else {
                HideLoader($('#loaderca'));
            }

    }
    var stream;
    async function captureAgain() {
        var vid = document.getElementById("inputVideo");

        capturedCanvas = [];
        if (isOn == true) {
            ShowLoader($('#loaderca'));
            vid.play();
            caputreImageIndex = 1;
            await faceapi.loadTinyFaceDetectorModel('/')
            await faceapi.loadFaceLandmarkTinyModel('/')
            await faceapi.loadFaceRecognitionModel('/')
             stream = await navigator.mediaDevices.getUserMedia({ video: {} })
            const videoEl = $('#inputVideo').get(0)
            videoEl.srcObject = stream
        } else {
                ShowNotification("Camera is Off, Please switch on your camera", "error")
            }
    }

    async function capture() {
        const inputImgEl = $('#inputVideo').get(0)
        const options = getFaceDetectorOptions()

        const detections = await faceapi.detectAllFaces(inputImgEl, options)
        //const detections = await faceapi.detectSingleFace(inputImgEl, options).withFaceLandmarks(useTinyModel)
        //    .withFaceDescriptor()

        const faceImages = await faceapi.extractFaces(inputImgEl, detections)
        displayExtractedFaces(faceImages);
        if (caputreImageIndex == 6) {
            document.getElementById("uploadCapturedImages").style.display = "";
        }
    }

    async function addLabelDecriptors() {

        for (var c = 0; c <= capturedCanvas.length - 1; c++) {
            var imageResult = await faceapi.computeFaceDescriptor(capturedCanvas[c]);
            descriptors.push(imageResult);
        }
        var labeledFaceDescriptor = new faceapi.LabeledFaceDescriptors(
            '@Model.LoggedInAsByUserName',
            descriptors
        );
        labeldescriptors.push(labeledFaceDescriptor)
        console.log("Label");
        console.log(labeldescriptors);
        HideLoader($('#loaderca'));
    }

    function displayExtractedFaces(faceImages) {
        const canvas = $('#overlay').get(0)
        faceapi.matchDimensions(canvas, $('#inputVideo').get(0))

        $('#div' + caputreImageIndex).empty()
        if (caputreImageIndex <= 5) {
            ShowLoader($('#loaderca'));
            canvas.width = 100;
            canvas.height = 100;
            faceImages.forEach(canvas => $('#div' + caputreImageIndex).append(canvas))
            capturedCanvas.push(canvas);
            console.log(capturedCanvas);
            caputreImageIndex++;
        }
    }


    $(document).ready(async function () {

        //await run();
        $("#User").kendoDropDownList({
            dataTextField: "Name",
            dataValueField: "Id",
            filter: "contains",
	    optionLabel:"Select User",
            dataSource:
            {
                transport:
                {
                    read:
                    {
                        url: "/Cms/User/GetUserIdNameList",
                    }
                }
            }
        });

    })

    async function run() {
        await faceapi.loadTinyFaceDetectorModel('/')
        await faceapi.loadFaceLandmarkTinyModel('/')
        await faceapi.loadFaceRecognitionModel('/')
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
        const videoEl = $('#inputVideo').get(0)
        videoEl.srcObject = stream
    }

    function onSaveFaces() {
        var value = $("#User").data("kendoDropDownList").value();

        if (value != null && value != "") {
            document.getElementById("uploadCapturedImages").style.display = "none";
            ShowLoader($('#loaderca'));

            var obj = encodeDescriptors(descriptors);



            var data = {
                Id: value,//'@Model.UserId',
                Code: obj,
            };

            $.ajax({
                type: "POST",
                url: "/cms/user/registerFaceDecriptors",
                data: data,
                dataType: "json",
                success: function (result) {
                    ShowNotification("Saved Successfully", "success");
                    HideLoader($('#loaderca'));
                },
                error: function (xhr, httpStatusMessage, customErrorMessage) {
                    HideLoader($('#loaderca'));
                    ShowNotification("Saved Successfully", "success");
                }
            });
        } else {
            ShowNotification("Please select user ", "error");
        }
    }

    function encodeDescriptors(obj) {
        var jsonStr = JSON.stringify(obj, function (key, value) {
            // the replacer function is looking for some typed arrays.
            // If found, it replaces it by a trio
            if (value instanceof Int8Array ||
                value instanceof Uint8Array ||
                value instanceof Uint8ClampedArray ||
                value instanceof Int16Array ||
                value instanceof Uint16Array ||
                value instanceof Int32Array ||
                value instanceof Uint32Array ||
                value instanceof Float32Array ||
                value instanceof Float64Array) {
                var replacement = {
                    constructor: value.constructor.name,
                    data: Array.apply([], value),
                    flag: Float32Array
                }
                return replacement;
            }
            return value;
        });
        return jsonStr;
    }
    var vid = document.getElementById("inputVideo");
    var localStream;
    async function onCamera() {
        document.getElementById("waterMark").style.display = "none";
        document.getElementById("inputVideo").style.display = "";
        //await run();
       navigator.mediaDevices.getUserMedia({
           audio: true,
           video: true
       })
           .then(stream => {
               var vid = document.getElementById("inputVideo");

               localStream = stream;
               vid.srcObject = stream;
               isOn = true;
               //audio.srcObject = stream;
           })
           .catch((err) => {
               console.log(err);
           });
    }
    var isOn = false;

    async function offCamera() {
        debugger;
        document.getElementById("waterMark").style.display = "";
        document.getElementById("inputVideo").style.display = "none";
        //localStream.getVideoTracks()[0].stop();
        //vid.src = '';
        isOn = false;

        const video = document.querySelector('video');

        // A video's MediaStream object is available through its srcObject attribute
        const mediaStream = video.srcObject;

        // Through the MediaStream, you can get the MediaStreamTracks with getTracks():
        const tracks = mediaStream.getTracks();

        // Tracks are returned as an array, so if you know you only have one, you can stop it with:
        tracks[0].stop();

        // Or stop all like so:
        tracks.forEach(track => track.stop())
    }
</script>

<div class="row">

    <div class="col">
        <div id="waterMark" style="margin-top:2%; font-size:25px">  <span class="fas fa-camera" style="margin-right:1%"> </span>Switch On Camera</div>

        <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
        <canvas class="transparent" id="overlay"></canvas>
        <div id="facesContainer"></div>
    </div>


    <div class="col">
        <br />
        @*@(Html.Kendo().DropDownList().Name("User")
        .OptionLabel("Select User")
        .DataSource(source =>
        {
            source.Read(read =>
        {
            read.Action("GetUserIdNameList", "User", new { area = "CMS" });
        });
        })
        .DataTextField("Name")
        .DataValueField("Id")
        .Filter(FilterType.Contains)
        .AutoBind(true)
        .HtmlAttributes(new { @class = "hr-xx-large" }))*@
    <input id="User" class="hr-xx-large" />
        <br /> <br />
        <div class="row">
            <div id="div1" class="col capture-img">  <img id="face1" src="/images/200.png" class="capture-img" />     </div>
            <div id="div2" class="col capture-img">  <img id="face2" src="/images/200.png" class="capture-img" />     </div>
            <div id="div3" class="col capture-img">  <img id="face3" src="/images/200.png" class="capture-img" />     </div>
            <div id="div4" class="col capture-img">  <img id="face4" src="/images/200.png" class="capture-img" />     </div>
            <div id="div5" class="col capture-img">  <img id="face5" src="/images/200.png" class="capture-img" />     </div>
        </div>
        <br />

        <div>
            <button id="start" class="btn btn-primary" onclick="onCamera()"> On </button>
            <button id="off" class="btn btn-secondary" onclick="offCamera()"> Off </button>
            <button id="resetImages" class="btn btn-secondary" style="background-color:red" onclick="captureAgain()">Capture Face</button>
            <button id="uploadCapturedImages" style="display:none" class="btn btn-primary" onclick="onSaveFaces()">Save Faces</button>
            <div id="loaderca"></div>
        </div>
    </div>

</div>

<style>
    .transparent {
        background: rgba(255,255,255,0.5);
    }

    .capture-img {
        width: 100px;
        height: 100px;
    }

    canvas {
        height: 100px;
        width: 100px;
    }
</style>